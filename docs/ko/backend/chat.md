# 채팅 및 컨텍스트 관리 개요

---

## 컨텍스트 관리

### 시스템 프롬프트

시스템 프롬프트는 시스템과 함께 패키징된 기본 프롬프트입니다. 사용자는 기본 프롬프트를 편집할 수 있으며 데이터베이스에 저장됩니다.

시스템 프롬프트의 일부는 동적으로 업데이트/삽입됩니다:
- 메시지 전송 날짜/시간
- 해당 사이클에서 특정 도구 사용 가능 여부에 따른 도구 설명
- 사용자가 검색 관련 도구를 방금 호출한 경우 인용 섹션 포함

### 커스텀 에이전트 프롬프트

커스텀 에이전트 프롬프트는 최신 사용자 메시지 위의 사용자 메시지로 삽입됩니다. 사용자가 더 많은 메시지를 보내면 이력에서 동적으로 이동합니다.

사용자가 시스템 프롬프트를 완전히 대체하기로 선택한 경우, 커스텀 에이전트 프롬프트가 시스템 프롬프트를 대체하며 이력을 따라 이동하지 않습니다.

### 파일 처리

업로드 시 파일은 토큰이 처리됩니다. 컨텍스트에 맞는 토큰이 너무 많으면 포함 실패로 간주됩니다.

- 모든 LLM에 대해 알려진 토크나이저가 없을 경우 기본 토크나이저 사용
- 파일 업로드는 두 단계로 이루어짐: 실제 업로드 + 토큰 카운팅
- 파일은 "특정 시점" 포함으로 채팅 컨텍스트에 추가되며 대화가 진행됨에 따라 컨텍스트 창에서 위로 이동

이미지 파일도 사용자 메시지에 특정 시점 포함으로 첨부됩니다.

### 프로젝트

프로젝트에 포함된 파일이 모델 컨텍스트에 모두 맞을 만큼 적으면, LLM이 쉽게 접근할 수 있도록 이력의 끝에 가깝게 유지합니다.

프로젝트 파일은 벡터화되어 검색 엔진에 저장됩니다. 사용자가 프로젝트의 토큰 수보다 작은 컨텍스트를 가진 모델을 선택하면 프로젝트 파일에 RAG를 적용합니다.

### 문서 표현 방식

검색 또는 업로드된 문서는 LLM이 쉽게 이해할 수 있도록 JSON으로 표현됩니다:

```json
{
    "documents": [
        {"document": 1, "title": "안녕하세요", "metadata": "status closed", "contents": "내용"},
        {"document": 2, "title": "세상", "contents": "바"}
    ]
}
```

- 문서는 LLM이 단일 번호로 인용할 수 있도록 표현됩니다.
- 검색 도구는 URL도 LLM에 제공하여 `open_url` 도구를 호출할 수 있습니다.

### 리마인더

LLM이 특정 지침을 따르도록 보장하기 위해, 채팅 컨텍스트 끝에 사용자 메시지로 지침이 추가됩니다.

- 검색 관련 도구가 사용된 경우 인용 리마인더는 항상 추가됩니다.
- 기본적으로 리마인더 없음. 사용자가 리마인더를 설정하면 마지막 메시지에 추가됩니다.

### 도구 호출

도구 호출 응답은 매우 길어질 수 있으므로 (내부 검색이 수천 토큰일 수 있음), 오늘날 도구 응답은 "더 이상 사용할 수 없음"을 나타내는 하드코딩된 문자열로 대체됩니다. 검색 쿼리 및 기타 인수와 같은 도구 호출 세부 사항은 이력에 유지됩니다.

---

## 컨텍스트 흐름 예시

```
S  = 시스템 메시지
CA = 사용자 메시지로서의 커스텀 에이전트
A  = 에이전트 응답 메시지
U  = 사용자 메시지
TC = 도구 호출 에이전트 메시지
TR = 도구 응답
R  = 리마인더
F  = 특정 시점 파일
P  = 프로젝트 파일

커스텀 에이전트를 사용하는 흐름:
S, U1, TC, TR, A1, CA, U2, A2
→ 다음 메시지 전송: S, U1, TC, TR, A1, U2, A2, CA, U3, TC, TR, R, A3

프로젝트 및 파일 업로드 흐름:
S, CA, P, F, U1, A1
→ 다음 메시지 전송: S, F, U1, A1, CA, P, U2, A2
```

---

## LLM 흐름 아키텍처

### 주요 개념

- **턴(Turn)**: 사용자가 메시지를 보내고 AI가 일련의 작업 후 응답하는 단위
- **스텝/사이클(Step/Cycle)**: 특정 컨텍스트와 도구가 주어진 단일 LLM 추론

### 1. 최상위 레이어 (`process_message` 함수)

설정 및 검증 레이어로, 다음을 수행합니다:
- 요청 검증
- 세션의 채팅 이력 구성
- 파일 및 이미지 같은 추가 컨텍스트 가져오기
- LLM을 위한 모든 도구 준비
- 루프에서 사용할 상태 컨테이너 객체 생성

#### 래퍼 (`run_chat_loop_with_state_containers`)

LLM 흐름을 백그라운드 스레드에서 실행하고 이미터에서 정지 신호를 모니터링합니다:
- 최상위 레이어는 LLM 흐름과 가능한 한 격리되어 패킷을 즉시 yield 할 수 있습니다.
- 하위 레벨이 실패해도 최상위 레이어가 사용자에게 합리적인 응답을 보장합니다.
- 모든 저장 및 DB 작업은 하위 레벨에서 추상화됩니다.

#### 이미터

이미터는 하위 레벨이 최상위까지 객체를 yield하지 않아도 되는 객체 큐입니다:
- 함수를 더 잘 설계할 수 있습니다 (모든 것이 제너레이터일 필요 없음).
- 더 쉽게 테스트할 수 있습니다.
- 이미터와 상태 컨테이너는 변이 상태 객체입니다.
- 이미터는 패킷만 받아야 하며 다른 용도로 사용하면 안 됩니다.

#### 상태 컨테이너

LLM 흐름 중 상태를 축적하는 데 사용됩니다:
- 논리에 사용하지 말고, 상태 축적에만 사용하세요.
- 답변 토큰, 추론 토큰, 도구 호출, 인용 정보 등을 수집합니다.
- 하위 레이어가 완료된 후 모든 상태를 읽고 DB에 저장합니다.

#### 생성 중지

중지 신호는 래퍼가 300ms마다 확인합니다. 신호 자체는 Redis에 저장되며 사용자가 중지 엔드포인트를 호출하여 설정합니다. 하위 레벨은 중지 신호에 대해 전혀 알지 못합니다.

---

### 2. LLM 루프 (`run_llm_loop` 함수)

턴의 로직을 처리합니다. 기본적으로 while 루프로, 다음을 수행합니다:
- LLM 추론을 위한 컨텍스트 변환 및 잘라내기
- 리마인더, 시스템 프롬프트 업데이트 같은 컨텍스트 수정자 추가
- 도구 호출 실행 및 결과 수집
- 상태 컨테이너에 저장될 일부 객체 구성

### 3. LLM 스텝 (`run_llm_step` 함수)

단일 LLM 추론입니다. LLM 스트림 함수의 래퍼로:
- 이미터가 개별 토큰을 즉시 emit할 수 있도록 패킷 변환 처리
- 다른 섹션(추론, 답변, 도구 호출)이 동시에 오지 않으므로 추적
- 다른 도구 호출을 추적하고 LLM 루프에 반환하여 실행

---

## 알아야 할 사항

- 패킷은 `turn_index` 필드로 레이블이 지정됩니다. 이것은 백엔드 개념의 턴과 같지 않습니다. 프론트엔드의 `turn_index`는 이 패킷이 어느 블록에 속하는지를 나타냅니다.
- "메시지"의 3가지 표현:
  1. **`ChatMessage`** (DB 모델): 변환되어 깊은 흐름에서 사용하지 않아야 함
  2. **`ChatMessageSimple`** (데이터 모델): 코드 전반에서 가능한 많이 사용해야 하는 풍부한 표현
  3. **`LanguageModelInput`** (LLM 인터페이스): LLM 인터페이스 레이어를 위한 최대한 간단한 표현
